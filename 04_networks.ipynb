{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f202147e",
   "metadata": {},
   "source": [
    "# Spatial and Similarity Networks\n",
    "\n",
    "This notebook builds two types of networks for Chicago Community Areas. The first network is a spatial adjacency graph where two areas are connected if their boundaries touch. This graph is used to study spatial spillovers and the extent to which saturated or underserved areas cluster in space.\n",
    "\n",
    "The second network is a similarity graph based on amenity density and demographic structure. Community Areas are connected when their feature vectors are highly similar. This graph reveals clusters of neighborhoods that share comparable profiles, even if they are far apart in geographic space.\n",
    "\n",
    "For both networks, the notebook attaches attributes such as the saturation index, hardship index, and per capita income to each node. It then computes simple centrality measures and exports summaries for use in the final analysis and visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db999f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d39bba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged geometry and attributes. Rows: 77\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1. Load data and geometry\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(\"saturation_index_by_CA.csv\")\n",
    "\n",
    "df[\"ca_name\"] = df[\"ca_name\"].str.upper().str.strip()\n",
    "\n",
    "# Load Community Area boundaries\n",
    "ca_boundaries_url = \"https://data.cityofchicago.org/resource/igwz-8jzy.geojson\"\n",
    "ca = gpd.read_file(ca_boundaries_url).to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Standardize names\n",
    "ca = ca.rename(columns={\"area_numbe\": \"ca_num\", \"community\": \"ca_name\"})\n",
    "ca[\"ca_num\"] = ca[\"ca_num\"].astype(int)\n",
    "ca[\"ca_name\"] = ca[\"ca_name\"].str.upper().str.strip()\n",
    "\n",
    "# Join attributes\n",
    "gdf = ca.merge(df, on=[\"ca_num\", \"ca_name\"], how=\"left\")\n",
    "\n",
    "print(\"Merged geometry and attributes. Rows:\", gdf.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c516fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of adjacency edges: 197\n",
      "Adjacency graph nodes: 77\n",
      "Adjacency graph edges: 197\n",
      "Saved adjacency network centrality and graph.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------\n",
    "# 2. Spatial adjacency network\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "neighbors = gpd.sjoin(\n",
    "    gdf[[\"ca_num\", \"ca_name\", \"geometry\"]],\n",
    "    gdf[[\"ca_num\", \"ca_name\", \"geometry\"]],\n",
    "    how=\"inner\",\n",
    "    predicate=\"touches\"\n",
    ")\n",
    "\n",
    "neighbors = neighbors.rename(columns={\n",
    "    \"ca_num_left\": \"ca_num_i\",\n",
    "    \"ca_name_left\": \"ca_name_i\",\n",
    "    \"ca_num_right\": \"ca_num_j\",\n",
    "    \"ca_name_right\": \"ca_name_j\"\n",
    "})\n",
    "\n",
    "edges_adj = neighbors[\n",
    "    neighbors[\"ca_num_i\"] != neighbors[\"ca_num_j\"]\n",
    "][[\"ca_num_i\", \"ca_num_j\"]].drop_duplicates()\n",
    "\n",
    "edges_adj = pd.DataFrame(\n",
    "    np.sort(edges_adj.values, axis=1),\n",
    "    columns=[\"ca_num_i\", \"ca_num_j\"]\n",
    ").drop_duplicates()\n",
    "\n",
    "print(\"Number of adjacency edges:\", edges_adj.shape[0])\n",
    "\n",
    "# Create graph\n",
    "G_adj = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for _, row in gdf.iterrows():\n",
    "    G_adj.add_node(\n",
    "        int(row[\"ca_num\"]),\n",
    "        ca_name=row[\"ca_name\"],\n",
    "        saturation_index=row.get(\"saturation_index\", None),\n",
    "        hardship_index=row.get(\"hardship_index\", None),\n",
    "        per_capita_income=row.get(\"per_capita_income\", None)\n",
    "    )\n",
    "\n",
    "# Add edges\n",
    "for _, row in edges_adj.iterrows():\n",
    "    G_adj.add_edge(int(row[\"ca_num_i\"]), int(row[\"ca_num_j\"]))\n",
    "\n",
    "print(\"Adjacency graph nodes:\", G_adj.number_of_nodes())\n",
    "print(\"Adjacency graph edges:\", G_adj.number_of_edges())\n",
    "\n",
    "# Degree centrality\n",
    "deg_centrality_adj = nx.degree_centrality(G_adj)\n",
    "\n",
    "centrality_adj_df = pd.DataFrame({\n",
    "    \"ca_num\": list(deg_centrality_adj.keys()),\n",
    "    \"degree_centrality_adj\": list(deg_centrality_adj.values())\n",
    "}).merge(\n",
    "    df[[\"ca_num\", \"ca_name\", \"saturation_index\"]],\n",
    "    on=\"ca_num\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "centrality_adj_df.to_csv(\"adjacency_network_centrality.csv\", index=False)\n",
    "\n",
    "# Save graph using pickle\n",
    "with open(\"adjacency_network.gpickle\", \"wb\") as f:\n",
    "    pickle.dump(G_adj, f)\n",
    "\n",
    "print(\"Saved adjacency network centrality and graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e21f844c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of similarity edges above threshold: 360\n",
      "Similarity graph nodes: 74\n",
      "Similarity graph edges: 360\n",
      "Saved similarity network centrality and graph.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Similarity network\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "feature_cols = [\n",
    "    \"saturation_index\",\n",
    "    \"scaled_business_license_count\",\n",
    "    \"scaled_food_inspections_count\",\n",
    "    \"scaled_liquor_license_count\",\n",
    "    \"scaled_building_permits_count\",\n",
    "    \"pct_dependents\",\n",
    "    \"per_capita_income\",\n",
    "    \"hardship_index\"\n",
    "]\n",
    "\n",
    "feature_cols = [c for c in feature_cols if c in gdf.columns]\n",
    "\n",
    "gdf_features = gdf.dropna(subset=feature_cols).copy()\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(gdf_features[feature_cols])\n",
    "\n",
    "# Cosine similarity matrix\n",
    "sim_matrix = cosine_similarity(X)\n",
    "\n",
    "similarity_threshold = 0.8\n",
    "sim_edges = []\n",
    "\n",
    "n = gdf_features.shape[0]\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        sim = sim_matrix[i, j]\n",
    "        if sim >= similarity_threshold:\n",
    "            sim_edges.append((\n",
    "                int(gdf_features.iloc[i][\"ca_num\"]),\n",
    "                int(gdf_features.iloc[j][\"ca_num\"]),\n",
    "                sim\n",
    "            ))\n",
    "\n",
    "print(\"Number of similarity edges above threshold:\", len(sim_edges))\n",
    "\n",
    "# Build similarity graph\n",
    "G_sim = nx.Graph()\n",
    "\n",
    "for _, row in gdf_features.iterrows():\n",
    "    G_sim.add_node(\n",
    "        int(row[\"ca_num\"]),\n",
    "        ca_name=row[\"ca_name\"],\n",
    "        saturation_index=row.get(\"saturation_index\", None),\n",
    "        hardship_index=row.get(\"hardship_index\", None),\n",
    "        per_capita_income=row.get(\"per_capita_income\", None)\n",
    "    )\n",
    "\n",
    "for ca_i, ca_j, sim in sim_edges:\n",
    "    G_sim.add_edge(ca_i, ca_j, weight=sim)\n",
    "\n",
    "print(\"Similarity graph nodes:\", G_sim.number_of_nodes())\n",
    "print(\"Similarity graph edges:\", G_sim.number_of_edges())\n",
    "\n",
    "# Degree centrality for similarity network\n",
    "deg_centrality_sim = nx.degree_centrality(G_sim)\n",
    "\n",
    "centrality_sim_df = pd.DataFrame({\n",
    "    \"ca_num\": list(deg_centrality_sim.keys()),\n",
    "    \"degree_centrality_sim\": list(deg_centrality_sim.values())\n",
    "}).merge(\n",
    "    df[[\"ca_num\", \"ca_name\", \"saturation_index\"]],\n",
    "    on=\"ca_num\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "centrality_sim_df.to_csv(\"similarity_network_centrality.csv\", index=False)\n",
    "\n",
    "# Save similarity graph\n",
    "with open(\"similarity_network.gpickle\", \"wb\") as f:\n",
    "    pickle.dump(G_sim, f)\n",
    "\n",
    "print(\"Saved similarity network centrality and graph.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
